{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies collector - deepdive tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/netdata/community/blob/main/netdata-agent-api/netdata-pandas/anomalies_collector_deepdive.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through, step by step, a worked example of how the [netdata anomalies collector](https://github.com/andrewm4894/netdata/tree/anomalies-collector/collectors/python.d.plugin/anomalies) works under the hood. \n",
    "\n",
    "**Note**: you can click the \"Open in Colab\" button above to open this notebook in [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true) where you can just get going with it without having to set up python environments or any messy stuff like that. If the button does not work then just [click here](https://colab.research.google.com/github/netdata/community/blob/main/netdata-agent-api/netdata-pandas/anomalies_collector_deepdive.ipynb).\n",
    "\n",
    "**Another Note**: If you are just reading through this notebook then it might be better to view it using nbviewer [here](https://nbviewer.jupyter.org/github/netdata/community/blob/main/netdata-agent-api/netdata-pandas/anomalies_collector_deepdive.ipynb) or colab [here](https://colab.research.google.com/github/netdata/community/blob/main/netdata-agent-api/netdata-pandas/anomalies_collector_deepdive.ipynb) as it will render a bit prettier than in Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to install required packages if needed (you will need to do this the first time if running in Google Colab).\n",
    "#!pip install netdata-pandas==0.0.28 numba==0.50.1 scikit-learn==0.23.2 pyod==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Overview](#Overview)\n",
    "- [Inputs & configuration](#Inputs-&-configuration)\n",
    "- [An aside on PCA](#An-aside-on-PCA)\n",
    "- [Initialize our models](#Initialize-our-models)\n",
    "- [Get training data](#Get-training-data)\n",
    "- [Preprocess or \"featurize\" the training data](#Preprocess-or-\"featurize\"-the-training-data)\n",
    "- [Train models](#Train-models)\n",
    "- [Get pediction data](#Get-pediction-data)\n",
    "- [Get predictions](#Get-predictions)\n",
    "- [But what _is_ the model?](#But-what-is-the-model?)\n",
    "- [Ok so lets step through that!](#Ok-so-lets-step-through-that!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, lets start with a meme..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](img/mlfunny.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main concepts central to what the anomalies collector does:\n",
    "\n",
    "- **Featurization**: This is how we take the raw data for each chart and preprocess it into a feature representation or \"[feature vector](https://en.wikipedia.org/wiki/Feature_(machine_learning\\))\" used by the model. A simple way to think of this is that we just take each row of data and add some extra columns to encode some additional information. For example, a smoothed average of the last `lags_n` values for each dimension on the chart so the model can have some knowledge of the recent past beyond just the latest raw values of the dimensions.\n",
    "\n",
    "- **Training**: A function to take our \"featurized\" training data and train our models, one for each chart (or [custom models](https://github.com/andrewm4894/netdata/tree/anomalies-collector/collectors/python.d.plugin/anomalies#custom-models) if you have defined any). This function will do slightly different things depending on what [model](https://pyod.readthedocs.io/en/latest/pyod.models.html#) you use. In a broad sense, its job is to train the model to form a useful, more compact, representation of the training data and then we can use this representation to measure our level of surprise at new data that we want to get anomaly scores for. So for the default PCA model this involves leveraging finding a lower dimensional representation that does a good job at reconstructing the main characteristics of the variance in our training data. Some other models might take a slightly different approach use different representations and algorithms to get to that \"measure of surprise\" for each feature vector. For the purpose of what we are doing this is largely abstracted away by the [API of the PyOD library](https://pyod.readthedocs.io/en/latest/pyod.html#api-reference), such that as a user we can easily switch between various models and still have broadly the same inputs ([Numpy arrays](https://numpy.org/doc/stable/reference/generated/numpy.array.html)) and outputs (also Numpy array's of anomaly scores, probabilities, and flags).\n",
    "\n",
    "- **Prediction**: Each trained model has a [`predict()`](https://pyod.readthedocs.io/en/latest/api_cc.html#pyod.models.base.BaseDetector.predict) function that we can use by passing in a new feature vector and getting back an anomaly probability and anomaly flag from the trained model. This is the part where we actually use the trained model as new data arrives to ask - \"how unusual does this new data look?\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.lib.display import YouTubeVideo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netdata_pandas.data import get_data, get_allmetrics\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "\n",
    "def make_features(df, lags_n, diffs_n, smooth_n):\n",
    "    \"\"\"Given a pandas dataframe preprocess it to take differences, add smoothing, and lags as specified. \n",
    "    \"\"\"\n",
    "    if diffs_n >= 1:\n",
    "        # take differences\n",
    "        df = df.diff(diffs_n).dropna()\n",
    "    if smooth_n >= 2:\n",
    "        # apply a rolling average to smooth out the data a bit\n",
    "        df = df.rolling(smooth_n).mean().dropna()\n",
    "    if lags_n >= 1:\n",
    "        # for each dimension add a new columns for each of lags_n lags of the differenced and smoothed values for that dimension\n",
    "        df_columns_new = [f'{col}_lag{n}' for n in range(lags_n+1) for col in df.columns]\n",
    "        df = pd.concat([df.shift(n) for n in range(lags_n + 1)], axis=1).dropna()\n",
    "        df.columns = df_columns_new\n",
    "    # sort columns to have lagged values next to each other for clarity when looking at the feature vectors\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs & configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we will define all the inputs we will use in this tutorial. Feel free to play with them once you are familiar with how it all hangs together.\n",
    "\n",
    "Below you will see that the paramater values map to a subset of the inputs (the most important ones to help explain whats going on) required as part of the [`anomalies.conf`](https://github.com/andrewm4894/netdata/blob/anomalies-collector/collectors/python.d.plugin/anomalies/anomalies.conf) configuration for the [anomalies collector](https://github.com/andrewm4894/netdata/blob/anomalies-collector/collectors/python.d.plugin/anomalies) itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# what host will we use\n",
    "host = 'london.my-netdata.io'\n",
    "\n",
    "# for this tutorial we will just use a few charts\n",
    "charts_in_scope = ['system.cpu', 'system.load', 'system.net', 'system.io']\n",
    "\n",
    "# what model from PyOD will we use under the hood\n",
    "model = 'pca'\n",
    "\n",
    "# how many seconds of data will we train our models on\n",
    "train_n_secs = 14400\n",
    "\n",
    "# what contamination rate will we use, see some discussion here to understand this one more: https://github.com/yzhao062/pyod/issues/144\n",
    "contamination = 0.001\n",
    "\n",
    "# if we want to ignore a recent window of data when training the model we can use this\n",
    "offset_n_secs = 0\n",
    "\n",
    "# how many lags to include in our feature vector\n",
    "lags_n = 5\n",
    "\n",
    "# how much smoothing to apply in our feature vector\n",
    "smooth_n = 3\n",
    "\n",
    "# if we want to do everything in terms of differences then we set diffs_n=1\n",
    "diffs_n = 1\n",
    "\n",
    "# for purpose of this turorial how many prediction steps will we take once we have a trained model\n",
    "n_prediction_steps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside on PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the anomalies collector uses the `PCA` model, primarily this is because the PCA model gives a good combination of being able to capture and model flexible patterns in the data while also being computationally cheap since under the hood it is using the well researched, optimized and understood [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition) algorithm to decompose our featurized data and project it onto a lower dimensional space. At a high level, when we see new data that is in a strange or unexpected part of this lower dimensional space then this is symptomatic of some anomalous data and so will get a higher anomaly score. \n",
    "\n",
    "- api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca\n",
    "- source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/pca.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you want to learn more about PCA and play with some notebooks exploring PCA in a similar manner to this one then check out [this chapter](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html) from the great [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook) by [Jake Vander Plas](https://twitter.com/jakevdp).\n",
    "\n",
    "The image below (taken from the book) gives a good intuition about a way of thinking of PCA as (almost) dimensionality reduction. In the image below we are looking at how PCA could be used to \"compress\" the X and Y data into one single dimension of numbers by projecting each pair of points onto the corresponding solid blue line of dots. \n",
    "\n",
    "![image](img/pca1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if a [Computerfile](https://www.youtube.com/channel/UC9-y-6csu5WGm29I7JiwpnA) video is more your thing then check out the below one as it does a better job then we can here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/TJdH6rPA-TI\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1247d5a65b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo('TJdH6rPA-TI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sense the PCA is learning a compressed representation of the data (technically, as mentioned in the video above, its a transformed representation in a different space, but we dont need to get too bogged down in that for our purposes here). This is essentially how PyOD uses PCA for anomaly detection under the hood. \n",
    "\n",
    "So we use PCA to learn a compressed representation of all the training data for each chart is some more abstract lower dimensional space that can be of use to us. The \"of use to us\" part here comes from the fact that PCA picks these lower dimensional representations in a clever way (using [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition)) that maximises the amount of information about the main directions of variance of the original dataset. e.g. in the image above the line of blue dots is the best line we could project our data onto in order to maintain as much information as possible about the variance of the original 2 dimensional dataset, as you can see there is much more 'spread' in the data along the original x-axis than the y-axis and that is what is captured by the 'spread' in the solid blue line of dots.  \n",
    "\n",
    "So when we see a new observation if it does not map well into this lower level representation we have learned during training, then that tells us that this new observation does not fit well into the representation we learned during training and as such it's probably somewhat anomalous, at least in comparison to what we observed in general in our training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We have looked at PCA a little bit above, but the point of awesome libraries like PyOD is that you don't really need to go that far down into the details - once you understand how the API works and a little bit about the various types of models/approaches used you can consider playing with and trying out other models on your data that take completely different approaches under the hood, for example:\n",
    "\n",
    "- **hbos**: uses histograms as the underlying representations of your data used to then measure the surprise of new data ([more info](https://www.dfki.de/fileadmin/user_upload/import/6431_HBOS-poster.pdf)).\n",
    "- **cblof**: somewhat similar in approach to pca but learned clusters as the representation of your training data and then it's the distance of new observations to the learned cluster centroids that is used to generate an anomaly score ([a good blog post](http://towardsdatascience.com/local-outlier-factor-for-anomaly-detection-cc0c770d2ebe)).\n",
    "- **iforest**: uses a [isolation forest](https://en.wikipedia.org/wiki/Isolation_forest) as the underlying model and then observations that end up on strnage partso f that learned forest are then considered more anomalous ([sklearn user guide](https://scikit-learn.org/stable/modules/outlier_detection.html#isolation-forest)). \n",
    "- ...[etc](https://pyod.readthedocs.io/en/latest/pyod.models.html).\n",
    "\n",
    "**Note**: Not all models from PyOD have been implemented in the anomalies collector as some turned out to be too expensive for the specific use case of unsupervised anomaly detection on your Netdata node itself (or even on a parent node). To that end, the models available in the collector are [`pca`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca), [`hbos`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos), [`iforest`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest), [`cblof`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof), [`loda`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loda), [`copod`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.copod) or [`feature_bagging`](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.feature_bagging).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialize a PyOD model for each chart in `charts_in_scope`. Each model type in PyOD will have various different input parameters that a user can play with, we will tend to use the defaults and override them sometimes with ones we have picked based on what we know about the task we are working on. Generally these model parameters, apart from `contamination`, are hardcoded into the anomalies collector based on our internal research as we developed the collector, you can see this in the [collector code here](https://github.com/andrewm4894/netdata/blob/anomalies-collector/collectors/python.d.plugin/anomalies/anomalies.chart.py#L77).\n",
    "\n",
    "In the cell below we have added a comment for the source and API reference of each model from PyOD so you can take a look and read more about each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model for each chart\n",
    "if model == 'pca':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/pca.html\n",
    "    models = {c: PCA(contamination=contamination, n_components=2, n_selected_components=2) for c in charts_in_scope}\n",
    "elif model == 'hbos':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/hbos.html\n",
    "    models = {c: HBOS(contamination=contamination) for c in charts_in_scope}\n",
    "elif model == 'cblof':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/cblof.html\n",
    "    models = {c: CBLOF(contamination=contamination, n_clusters=4) for c in charts_in_scope}\n",
    "elif model == 'iforest':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/iforest.html\n",
    "    models = {c: IForest(contamination=contamination, n_estimators=50, bootstrap=True, behaviour='new') for c in charts_in_scope}\n",
    "else:\n",
    "    # we used the HBOS as default as it is both fast and robust to many different types of data and has proven in internal development \n",
    "    # to have less failure modes then some other models given the wide variaty of data we are expecting to be thrown at it\n",
    "    models = {c: HBOS(contamination=contamination) for c in charts_in_scope}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is get our raw training data for each chart we want to build a model for.\n",
    "\n",
    "To get the data we will make use of the [netdata-pandas](https://github.com/netdata/netdata-pandas) library we have built to make multiple asynchronous calls (using [asks](https://github.com/theelous3/asks) and [trio](https://github.com/python-trio/trio)) to the [Netdata REST API](https://learn.netdata.cloud/docs/agent/web/api) and basically wrangle the results into a nice [Pandas](https://pandas.pydata.org/) [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14400 entries, 1603996438 to 1604010837\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   system.cpu|guest       14400 non-null  float32\n",
      " 1   system.cpu|guest_nice  14400 non-null  float32\n",
      " 2   system.cpu|iowait      14400 non-null  float32\n",
      " 3   system.cpu|irq         14400 non-null  float32\n",
      " 4   system.cpu|nice        14400 non-null  float32\n",
      " 5   system.cpu|softirq     14400 non-null  float32\n",
      " 6   system.cpu|steal       14400 non-null  float32\n",
      " 7   system.cpu|system      14400 non-null  float32\n",
      " 8   system.cpu|user        14400 non-null  float32\n",
      " 9   system.io|in           14400 non-null  float32\n",
      " 10  system.io|out          14400 non-null  float32\n",
      " 11  system.load|load1      14398 non-null  float32\n",
      " 12  system.load|load15     14398 non-null  float32\n",
      " 13  system.load|load5      14398 non-null  float32\n",
      " 14  system.net|received    14400 non-null  float32\n",
      " 15  system.net|sent        14400 non-null  float32\n",
      "dtypes: float32(16)\n",
      "memory usage: 1012.5 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest</th>\n",
       "      <th>system.cpu|guest_nice</th>\n",
       "      <th>system.cpu|iowait</th>\n",
       "      <th>system.cpu|irq</th>\n",
       "      <th>system.cpu|nice</th>\n",
       "      <th>system.cpu|softirq</th>\n",
       "      <th>system.cpu|steal</th>\n",
       "      <th>system.cpu|system</th>\n",
       "      <th>system.cpu|user</th>\n",
       "      <th>system.io|in</th>\n",
       "      <th>system.io|out</th>\n",
       "      <th>system.load|load1</th>\n",
       "      <th>system.load|load15</th>\n",
       "      <th>system.load|load5</th>\n",
       "      <th>system.net|received</th>\n",
       "      <th>system.net|sent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603996438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505050</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.99427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.324799</td>\n",
       "      <td>-293.233490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.505050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.00573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.518410</td>\n",
       "      <td>-297.014709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>1.002506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.040840</td>\n",
       "      <td>-278.260101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.884140</td>\n",
       "      <td>-184.533005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>1.259446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.388489</td>\n",
       "      <td>-314.843994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest  system.cpu|guest_nice  system.cpu|iowait  \\\n",
       "time_idx                                                                 \n",
       "1603996438               0.0                    0.0                0.0   \n",
       "1603996439               0.0                    0.0                0.0   \n",
       "1603996440               0.0                    0.0                0.0   \n",
       "1603996441               0.0                    0.0                0.0   \n",
       "1603996442               0.0                    0.0                0.0   \n",
       "\n",
       "            system.cpu|irq  system.cpu|nice  system.cpu|softirq  \\\n",
       "time_idx                                                          \n",
       "1603996438             0.0              0.0                 0.0   \n",
       "1603996439             0.0              0.0                 0.0   \n",
       "1603996440             0.0              0.0                 0.0   \n",
       "1603996441             0.0              0.0                 0.0   \n",
       "1603996442             0.0              0.0                 0.0   \n",
       "\n",
       "            system.cpu|steal  system.cpu|system  system.cpu|user  \\\n",
       "time_idx                                                           \n",
       "1603996438          0.000000           0.505050         0.252525   \n",
       "1603996439          0.000000           0.757576         0.505050   \n",
       "1603996440          0.250627           0.250627         1.002506   \n",
       "1603996441          0.000000           0.503778         0.503778   \n",
       "1603996442          0.000000           0.503778         1.259446   \n",
       "\n",
       "            system.io|in  system.io|out  system.load|load1  \\\n",
       "time_idx                                                     \n",
       "1603996438           0.0      -34.99427                NaN   \n",
       "1603996439           0.0      -17.00573                NaN   \n",
       "1603996440           0.0        0.00000                0.0   \n",
       "1603996441           0.0        0.00000                0.0   \n",
       "1603996442           0.0        0.00000                0.0   \n",
       "\n",
       "            system.load|load15  system.load|load5  system.net|received  \\\n",
       "time_idx                                                                 \n",
       "1603996438                 NaN                NaN           178.324799   \n",
       "1603996439                 NaN                NaN            90.518410   \n",
       "1603996440                 0.0                0.0           120.040840   \n",
       "1603996441                 0.0                0.0           102.884140   \n",
       "1603996442                 0.0                0.0           353.388489   \n",
       "\n",
       "            system.net|sent  \n",
       "time_idx                     \n",
       "1603996438      -293.233490  \n",
       "1603996439      -297.014709  \n",
       "1603996440      -278.260101  \n",
       "1603996441      -184.533005  \n",
       "1603996442      -314.843994  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the window for the training data to pull\n",
    "before = int(datetime.now().timestamp()) - offset_n_secs\n",
    "after =  before - train_n_secs\n",
    "\n",
    "# get the training data\n",
    "df_train = get_data(hosts=host, charts=charts_in_scope, after=after, before=before, sort_cols=True, numeric_only=True, float_size='float32')\n",
    "print(df_train.info())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see our raw training data is just a pandas `DataFrame` with a timestamp index and a column of floats for each dimension from our `charts_in_scope` list.\n",
    "\n",
    "**Note**: The [netdata-pandas](https://github.com/netdata/netdata-pandas) default naming convention for columns is \"chart.name|dimension.name\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess or \"featurize\" the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model we will first do some preprocessing to the raw data to create a \"feature vector\" to try and encode a more flexible and powerful representation for the model to work with as opposed to just looking at the most recently observed values in isolation. \n",
    "\n",
    "This is the \"featurization\" we mentioned at the begining of the notebook. The idea here is to give the model some extra information so that it may spot more complex and interesting anomalies as opposed to just spikes where one metric is a very high or very low value.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14390, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest_lag0</th>\n",
       "      <th>system.cpu|guest_lag1</th>\n",
       "      <th>system.cpu|guest_lag2</th>\n",
       "      <th>system.cpu|guest_lag3</th>\n",
       "      <th>system.cpu|guest_lag4</th>\n",
       "      <th>system.cpu|guest_lag5</th>\n",
       "      <th>system.cpu|guest_nice_lag0</th>\n",
       "      <th>system.cpu|guest_nice_lag1</th>\n",
       "      <th>system.cpu|guest_nice_lag2</th>\n",
       "      <th>system.cpu|guest_nice_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>system.net|received_lag2</th>\n",
       "      <th>system.net|received_lag3</th>\n",
       "      <th>system.net|received_lag4</th>\n",
       "      <th>system.net|received_lag5</th>\n",
       "      <th>system.net|sent_lag0</th>\n",
       "      <th>system.net|sent_lag1</th>\n",
       "      <th>system.net|sent_lag2</th>\n",
       "      <th>system.net|sent_lag3</th>\n",
       "      <th>system.net|sent_lag4</th>\n",
       "      <th>system.net|sent_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603996448</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.809901</td>\n",
       "      <td>-70.385635</td>\n",
       "      <td>7.810880</td>\n",
       "      <td>43.855822</td>\n",
       "      <td>-16.635661</td>\n",
       "      <td>-48.705271</td>\n",
       "      <td>9.364441</td>\n",
       "      <td>12.798096</td>\n",
       "      <td>-14.211797</td>\n",
       "      <td>-9.447937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996449</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.566739</td>\n",
       "      <td>-38.809901</td>\n",
       "      <td>-70.385635</td>\n",
       "      <td>7.810880</td>\n",
       "      <td>-17.171773</td>\n",
       "      <td>-16.635661</td>\n",
       "      <td>-48.705271</td>\n",
       "      <td>9.364441</td>\n",
       "      <td>12.798096</td>\n",
       "      <td>-14.211797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.827042</td>\n",
       "      <td>58.566739</td>\n",
       "      <td>-38.809901</td>\n",
       "      <td>-70.385635</td>\n",
       "      <td>-48.912954</td>\n",
       "      <td>-17.171773</td>\n",
       "      <td>-16.635661</td>\n",
       "      <td>-48.705271</td>\n",
       "      <td>9.364441</td>\n",
       "      <td>12.798096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996451</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.409510</td>\n",
       "      <td>27.827042</td>\n",
       "      <td>58.566739</td>\n",
       "      <td>-38.809901</td>\n",
       "      <td>-79.684163</td>\n",
       "      <td>-48.912954</td>\n",
       "      <td>-17.171773</td>\n",
       "      <td>-16.635661</td>\n",
       "      <td>-48.705271</td>\n",
       "      <td>9.364441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.650205</td>\n",
       "      <td>1.409510</td>\n",
       "      <td>27.827042</td>\n",
       "      <td>58.566739</td>\n",
       "      <td>1.637634</td>\n",
       "      <td>-79.684163</td>\n",
       "      <td>-48.912954</td>\n",
       "      <td>-17.171773</td>\n",
       "      <td>-16.635661</td>\n",
       "      <td>-48.705271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest_lag0  system.cpu|guest_lag1  \\\n",
       "time_idx                                                   \n",
       "1603996448                    0.0                    0.0   \n",
       "1603996449                    0.0                    0.0   \n",
       "1603996450                    0.0                    0.0   \n",
       "1603996451                    0.0                    0.0   \n",
       "1603996452                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag2  system.cpu|guest_lag3  \\\n",
       "time_idx                                                   \n",
       "1603996448                    0.0                    0.0   \n",
       "1603996449                    0.0                    0.0   \n",
       "1603996450                    0.0                    0.0   \n",
       "1603996451                    0.0                    0.0   \n",
       "1603996452                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag4  system.cpu|guest_lag5  \\\n",
       "time_idx                                                   \n",
       "1603996448                    0.0                    0.0   \n",
       "1603996449                    0.0                    0.0   \n",
       "1603996450                    0.0                    0.0   \n",
       "1603996451                    0.0                    0.0   \n",
       "1603996452                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag0  system.cpu|guest_nice_lag1  \\\n",
       "time_idx                                                             \n",
       "1603996448                         0.0                         0.0   \n",
       "1603996449                         0.0                         0.0   \n",
       "1603996450                         0.0                         0.0   \n",
       "1603996451                         0.0                         0.0   \n",
       "1603996452                         0.0                         0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag2  system.cpu|guest_nice_lag3  ...  \\\n",
       "time_idx                                                            ...   \n",
       "1603996448                         0.0                         0.0  ...   \n",
       "1603996449                         0.0                         0.0  ...   \n",
       "1603996450                         0.0                         0.0  ...   \n",
       "1603996451                         0.0                         0.0  ...   \n",
       "1603996452                         0.0                         0.0  ...   \n",
       "\n",
       "            system.net|received_lag2  system.net|received_lag3  \\\n",
       "time_idx                                                         \n",
       "1603996448                -38.809901                -70.385635   \n",
       "1603996449                 58.566739                -38.809901   \n",
       "1603996450                 27.827042                 58.566739   \n",
       "1603996451                  1.409510                 27.827042   \n",
       "1603996452                -64.650205                  1.409510   \n",
       "\n",
       "            system.net|received_lag4  system.net|received_lag5  \\\n",
       "time_idx                                                         \n",
       "1603996448                  7.810880                 43.855822   \n",
       "1603996449                -70.385635                  7.810880   \n",
       "1603996450                -38.809901                -70.385635   \n",
       "1603996451                 58.566739                -38.809901   \n",
       "1603996452                 27.827042                 58.566739   \n",
       "\n",
       "            system.net|sent_lag0  system.net|sent_lag1  system.net|sent_lag2  \\\n",
       "time_idx                                                                       \n",
       "1603996448            -16.635661            -48.705271              9.364441   \n",
       "1603996449            -17.171773            -16.635661            -48.705271   \n",
       "1603996450            -48.912954            -17.171773            -16.635661   \n",
       "1603996451            -79.684163            -48.912954            -17.171773   \n",
       "1603996452              1.637634            -79.684163            -48.912954   \n",
       "\n",
       "            system.net|sent_lag3  system.net|sent_lag4  system.net|sent_lag5  \n",
       "time_idx                                                                      \n",
       "1603996448             12.798096            -14.211797             -9.447937  \n",
       "1603996449              9.364441             12.798096            -14.211797  \n",
       "1603996450            -48.705271              9.364441             12.798096  \n",
       "1603996451            -16.635661            -48.705271              9.364441  \n",
       "1603996452            -17.171773            -16.635661            -48.705271  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets preprocess or \"featurize\" our raw data\n",
    "df_train_processed = make_features(df_train, lags_n, diffs_n, smooth_n)\n",
    "\n",
    "# print out the shape of our featurized data\n",
    "print(df_train_processed.shape)\n",
    "df_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below few cells will explore a little what we have just done to try and make the ideas of preprocessing aka \"featurization\" aka \"feature vector\" a little clearer.\n",
    "\n",
    "Terms like \"featurization\" and \"feature vector\" are often used to sound fancy, but in reality its typically just as simple as adding additional columns to each row of your data where those new columns have numbers in them that represent something about your data that you want to make available to the model. \n",
    "\n",
    "So in our case adding lagged values of each smoothed and differenced dimension, is basically a design choice we make whereby we are telling the model we want it to consider `lags_n` recent values as opposed to just the latest observed dimensions. We do this because there are many [different types of anomalies](https://andrewm4894.com/2020/10/19/different-types-of-time-series-anomalies/) we want to try and be able to spot, so making a small snippet of recent data for each dimension available to the model gives us the ability to capture more complex anomaly patterns that might occur.\n",
    "\n",
    "If we were to just train the model on the most recent values for each dimension the best we could reasonably hope for it to capture would be anomalies where one or more dimension takes an unusually high or low value for one time step. This is essentially not that much better then a traditional approach using [z-scores](https://towardsdatascience.com/z-score-for-anomaly-detection-d98b0006f510). (If you are interested in comparing the two we actually also have a [zscores collector](https://github.com/andrewm4894/netdata/tree/zscores-collector/collectors/python.d.plugin/zscores) too, if, for example, you would like to just start simple or cannot install the ML Python libraries the anomalies collector depends on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape is (14400, 16)\n",
      "df_train_processed is (14390, 96)\n",
      "make_features has added 80 new columns, one for each lags_n (16*5=80)\n"
     ]
    }
   ],
   "source": [
    "# Lets look at how the shape of our data has changed due to preprocessing\n",
    "print(f'df_train shape is {df_train.shape}')\n",
    "print(f'df_train_processed is {df_train_processed.shape}')\n",
    "n_cols_added = len(df_train_processed.columns)-len(df_train.columns)\n",
    "print(f'make_features has added {n_cols_added} new columns, one for each lags_n ({df_train.shape[1]}*{lags_n}={n_cols_added})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see from the above output, our featurization has added a new column for each `lags_n` specified. And we have also lost a few rows due to `smooth_n` and `diffs_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be super clear lets look at the first few rows of training data for a specific metric before and after preprocessing. \n",
    "\n",
    "**Note**: Look at the last `time_idx` to see how the featurization works for a specific timestamp of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603996438</th>\n",
       "      <td>0.252525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996439</th>\n",
       "      <td>0.505050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996440</th>\n",
       "      <td>1.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996441</th>\n",
       "      <td>0.503778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996442</th>\n",
       "      <td>1.259446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996443</th>\n",
       "      <td>0.505050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996444</th>\n",
       "      <td>0.498753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996445</th>\n",
       "      <td>0.505050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996446</th>\n",
       "      <td>0.755668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996447</th>\n",
       "      <td>1.259446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user\n",
       "time_idx                   \n",
       "1603996438         0.252525\n",
       "1603996439         0.505050\n",
       "1603996440         1.002506\n",
       "1603996441         0.503778\n",
       "1603996442         1.259446\n",
       "1603996443         0.505050\n",
       "1603996444         0.498753\n",
       "1603996445         0.505050\n",
       "1603996446         0.755668\n",
       "1603996447         1.259446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'system.cpu|user'\n",
    "print('raw data')\n",
    "display(df_train[df_train.columns[df_train.columns.str.startswith(metric)]].head(1 + lags_n + smooth_n + diffs_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurized data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user_lag0</th>\n",
       "      <th>system.cpu|user_lag1</th>\n",
       "      <th>system.cpu|user_lag2</th>\n",
       "      <th>system.cpu|user_lag3</th>\n",
       "      <th>system.cpu|user_lag4</th>\n",
       "      <th>system.cpu|user_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603996448</th>\n",
       "      <td>0.082276</td>\n",
       "      <td>0.253564</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>-0.251465</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.165819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user_lag0  system.cpu|user_lag1  system.cpu|user_lag2  \\\n",
       "time_idx                                                                       \n",
       "1603996448              0.082276              0.253564              0.083539   \n",
       "\n",
       "            system.cpu|user_lag3  system.cpu|user_lag4  system.cpu|user_lag5  \n",
       "time_idx                                                                      \n",
       "1603996448             -0.251465             -0.001675             -0.165819  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('featurized data')\n",
    "display(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(metric)]].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manualy calculated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user</th>\n",
       "      <th>diff</th>\n",
       "      <th>smoothed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603996443</th>\n",
       "      <td>0.505050</td>\n",
       "      <td>-0.754395</td>\n",
       "      <td>-0.165819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996444</th>\n",
       "      <td>0.498753</td>\n",
       "      <td>-0.006297</td>\n",
       "      <td>-0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996445</th>\n",
       "      <td>0.505050</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>-0.251465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996446</th>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.250617</td>\n",
       "      <td>0.083539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603996447</th>\n",
       "      <td>1.259446</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>0.253564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user      diff  smoothed\n",
       "time_idx                                       \n",
       "1603996443         0.505050 -0.754395 -0.165819\n",
       "1603996444         0.498753 -0.006297 -0.001675\n",
       "1603996445         0.505050  0.006297 -0.251465\n",
       "1603996446         0.755668  0.250617  0.083539\n",
       "1603996447         1.259446  0.503778  0.253564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('manualy calculated')\n",
    "df_manual_example = df_train[df_train.columns[df_train.columns.str.startswith(metric)]].copy()\n",
    "# take diff\n",
    "df_manual_example['diff'] = df_manual_example[metric].diff(diffs_n)\n",
    "# apply smoothing\n",
    "df_manual_example['smoothed'] = df_manual_example['diff'].rolling(smooth_n).mean()\n",
    "display(df_manual_example.head(1 + lags_n + smooth_n + diffs_n).tail(1 + smooth_n + diffs_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see how one raw metric value is now being preprocessed to be a vector of `lags_n` differenced and smoothed values. It is this matrix of smoothed differences that the model will use for both training and when making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, if a chart has 2 dimensions and we have set `lags_n` to be 5 then our featurized 'matrix' of numbers will be a 2*(1+5) matrix. In reality this matrix is just flattened into a feature vector of 2 * (1+5) = 12 floating point values. The cell below shows this for the `system.net` chart as that is an example with 2 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n",
      "[[ 27.82704163  58.5667394  -38.80990092 -70.38563538   7.81088003\n",
      "   43.85582225 -16.63566081 -48.7052714    9.36444092  12.7980957\n",
      "  -14.21179708  -9.44793701]]\n"
     ]
    }
   ],
   "source": [
    "# lets look at our first feature vector for the 'system.net' model \n",
    "chart = 'system.net'\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(chart)]].head(1).shape)\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(chart)]].head(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our preprocessed training data we will train a model for each chart using our featurized data that represents each time step for each chart as a differenced, smoothed, and lagged matrix for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model for system.cpu using X_train of (14390, 54)\n",
      "train model for system.load using X_train of (14390, 18)\n",
      "train model for system.net using X_train of (14390, 12)\n",
      "train model for system.io using X_train of (14390, 12)\n"
     ]
    }
   ],
   "source": [
    "# loop over each chart in scope and train a model for each\n",
    "for chart in charts_in_scope:\n",
    "    # pull out the columns relating to the chart based on what thier name startswith and put it into a numpy array of values\n",
    "    X_train = df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(chart)]].values\n",
    "    print(f'train model for {chart} using X_train of {X_train.shape}')\n",
    "    # call the fit() method on each initialized model and pass it the full numpy array of our featurized training data\n",
    "    models[chart] = models[chart].fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have now trained our models, one for each chart based on our preprocessed training data. To be concrete we will look at some example obvervations our model has been trained on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp=1603996448\n",
      "feature vector for 0th training observation for system.cpu model:\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.0835422   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.08228797  0.          0.          0.16625103  0.\n",
      "  0.          0.          0.          0.          0.         -0.0835422\n",
      "  0.0822764   0.00167506  0.16750207  0.00042407 -0.00167506  0.08480796\n",
      "  0.0822764   0.25356423  0.08353901 -0.2514651  -0.00167506 -0.16581859]\n"
     ]
    }
   ],
   "source": [
    "# lets look at the first matrix or \"feature vector\" for our first model\n",
    "obs_n = 0\n",
    "model_n = 0\n",
    "print(f'timestamp={df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].index[obs_n]}')\n",
    "print(f'feature vector for {obs_n}th training observation for {charts_in_scope[model_n]} model:')\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].values[obs_n]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp=1603996449\n",
      "feature vector for 1th training observation for system.cpu model:\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.0835422   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.08228797  0.          0.          0.16625103\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.16792613  0.0822764   0.00167506  0.16750207  0.00042407 -0.00167506\n",
      "  0.          0.0822764   0.25356423  0.08353901 -0.2514651  -0.00167506]\n"
     ]
    }
   ],
   "source": [
    "# and the next one\n",
    "obs_n = 1\n",
    "model_n = 0\n",
    "print(f'timestamp={df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].index[obs_n]}')\n",
    "print(f'feature vector for {obs_n}th training observation for {charts_in_scope[model_n]} model:')\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].values[obs_n]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look close enough at the above two cells you will see the same values be shifted for each lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each matrix of numbers above _is_ the representation we give to our model of each time step. This is how the model views each chart - a matrix (\"feature vector\" to sound fancy) of floating point numbers encoding some differenced and smoothed information about the last `lags_n` observations for each dimension in the specific chart we are modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Within the anomalies collector, at some regular interval, as defined by `train_every_n` in the `anomalies.conf` file, we will repeat the above training step to retrain all models on the most recent window of available training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our trained models for each chart we can use them in looking at incoming observations and 'ask' the trained models how 'unusual' it thinks they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we now have 10 recent preprocessed feature vectors to predict on.\n"
     ]
    }
   ],
   "source": [
    "# define an empty dataframe we can store enough recent data into to generate our feature vector's for recent data on\n",
    "df_recent = pd.DataFrame()\n",
    "\n",
    "# simulate n_prediction_steps of getting latest data, making feature vecotr and getting predicitons\n",
    "for prediction_step in range(n_prediction_steps):\n",
    "    time.sleep(1) # sleep for a second to ensure getting a new timestamp from the host\n",
    "    df_latest = get_allmetrics(host=host, charts=charts_in_scope, wide=True)[df_train.columns]\n",
    "    df_latest['time_idx'] = int(time.time())\n",
    "    df_latest = df_latest.set_index('time_idx')\n",
    "    # just keep enough recent data to generate each feature vector\n",
    "    df_recent = df_recent.append(df_latest).tail((lags_n + smooth_n + diffs_n) * 2)\n",
    "    \n",
    "    # now lets featurize our recent data to be able to get predictions from the model for each observation\n",
    "    df_predict_processed = make_features(df_recent, lags_n, diffs_n, smooth_n)\n",
    "\n",
    "print(f'we now have {df_predict_processed.shape[0]} recent preprocessed feature vectors to predict on.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest_lag0</th>\n",
       "      <th>system.cpu|guest_lag1</th>\n",
       "      <th>system.cpu|guest_lag2</th>\n",
       "      <th>system.cpu|guest_lag3</th>\n",
       "      <th>system.cpu|guest_lag4</th>\n",
       "      <th>system.cpu|guest_lag5</th>\n",
       "      <th>system.cpu|guest_nice_lag0</th>\n",
       "      <th>system.cpu|guest_nice_lag1</th>\n",
       "      <th>system.cpu|guest_nice_lag2</th>\n",
       "      <th>system.cpu|guest_nice_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>system.net|received_lag2</th>\n",
       "      <th>system.net|received_lag3</th>\n",
       "      <th>system.net|received_lag4</th>\n",
       "      <th>system.net|received_lag5</th>\n",
       "      <th>system.net|sent_lag0</th>\n",
       "      <th>system.net|sent_lag1</th>\n",
       "      <th>system.net|sent_lag2</th>\n",
       "      <th>system.net|sent_lag3</th>\n",
       "      <th>system.net|sent_lag4</th>\n",
       "      <th>system.net|sent_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1604010851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.757464</td>\n",
       "      <td>67.487184</td>\n",
       "      <td>-43.596999</td>\n",
       "      <td>2.193788</td>\n",
       "      <td>68.874414</td>\n",
       "      <td>-28.777372</td>\n",
       "      <td>-49.792653</td>\n",
       "      <td>-88.506389</td>\n",
       "      <td>-8.619037</td>\n",
       "      <td>21.824389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604010852</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.064415</td>\n",
       "      <td>38.757464</td>\n",
       "      <td>67.487184</td>\n",
       "      <td>-43.596999</td>\n",
       "      <td>42.693629</td>\n",
       "      <td>68.874414</td>\n",
       "      <td>-28.777372</td>\n",
       "      <td>-49.792653</td>\n",
       "      <td>-88.506389</td>\n",
       "      <td>-8.619037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604010853</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.028883</td>\n",
       "      <td>-6.064415</td>\n",
       "      <td>38.757464</td>\n",
       "      <td>67.487184</td>\n",
       "      <td>35.970577</td>\n",
       "      <td>42.693629</td>\n",
       "      <td>68.874414</td>\n",
       "      <td>-28.777372</td>\n",
       "      <td>-49.792653</td>\n",
       "      <td>-88.506389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604010854</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.654248</td>\n",
       "      <td>-65.028883</td>\n",
       "      <td>-6.064415</td>\n",
       "      <td>38.757464</td>\n",
       "      <td>-29.928900</td>\n",
       "      <td>35.970577</td>\n",
       "      <td>42.693629</td>\n",
       "      <td>68.874414</td>\n",
       "      <td>-28.777372</td>\n",
       "      <td>-49.792653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604010856</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.692365</td>\n",
       "      <td>16.654248</td>\n",
       "      <td>-65.028883</td>\n",
       "      <td>-6.064415</td>\n",
       "      <td>-19.992321</td>\n",
       "      <td>-29.928900</td>\n",
       "      <td>35.970577</td>\n",
       "      <td>42.693629</td>\n",
       "      <td>68.874414</td>\n",
       "      <td>-28.777372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest_lag0  system.cpu|guest_lag1  \\\n",
       "time_idx                                                   \n",
       "1604010851                    0.0                    0.0   \n",
       "1604010852                    0.0                    0.0   \n",
       "1604010853                    0.0                    0.0   \n",
       "1604010854                    0.0                    0.0   \n",
       "1604010856                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag2  system.cpu|guest_lag3  \\\n",
       "time_idx                                                   \n",
       "1604010851                    0.0                    0.0   \n",
       "1604010852                    0.0                    0.0   \n",
       "1604010853                    0.0                    0.0   \n",
       "1604010854                    0.0                    0.0   \n",
       "1604010856                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag4  system.cpu|guest_lag5  \\\n",
       "time_idx                                                   \n",
       "1604010851                    0.0                    0.0   \n",
       "1604010852                    0.0                    0.0   \n",
       "1604010853                    0.0                    0.0   \n",
       "1604010854                    0.0                    0.0   \n",
       "1604010856                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag0  system.cpu|guest_nice_lag1  \\\n",
       "time_idx                                                             \n",
       "1604010851                         0.0                         0.0   \n",
       "1604010852                         0.0                         0.0   \n",
       "1604010853                         0.0                         0.0   \n",
       "1604010854                         0.0                         0.0   \n",
       "1604010856                         0.0                         0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag2  system.cpu|guest_nice_lag3  ...  \\\n",
       "time_idx                                                            ...   \n",
       "1604010851                         0.0                         0.0  ...   \n",
       "1604010852                         0.0                         0.0  ...   \n",
       "1604010853                         0.0                         0.0  ...   \n",
       "1604010854                         0.0                         0.0  ...   \n",
       "1604010856                         0.0                         0.0  ...   \n",
       "\n",
       "            system.net|received_lag2  system.net|received_lag3  \\\n",
       "time_idx                                                         \n",
       "1604010851                 38.757464                 67.487184   \n",
       "1604010852                 -6.064415                 38.757464   \n",
       "1604010853                -65.028883                 -6.064415   \n",
       "1604010854                 16.654248                -65.028883   \n",
       "1604010856                 19.692365                 16.654248   \n",
       "\n",
       "            system.net|received_lag4  system.net|received_lag5  \\\n",
       "time_idx                                                         \n",
       "1604010851                -43.596999                  2.193788   \n",
       "1604010852                 67.487184                -43.596999   \n",
       "1604010853                 38.757464                 67.487184   \n",
       "1604010854                 -6.064415                 38.757464   \n",
       "1604010856                -65.028883                 -6.064415   \n",
       "\n",
       "            system.net|sent_lag0  system.net|sent_lag1  system.net|sent_lag2  \\\n",
       "time_idx                                                                       \n",
       "1604010851             68.874414            -28.777372            -49.792653   \n",
       "1604010852             42.693629             68.874414            -28.777372   \n",
       "1604010853             35.970577             42.693629             68.874414   \n",
       "1604010854            -29.928900             35.970577             42.693629   \n",
       "1604010856            -19.992321            -29.928900             35.970577   \n",
       "\n",
       "            system.net|sent_lag3  system.net|sent_lag4  system.net|sent_lag5  \n",
       "time_idx                                                                      \n",
       "1604010851            -88.506389             -8.619037             21.824389  \n",
       "1604010852            -49.792653            -88.506389             -8.619037  \n",
       "1604010853            -28.777372            -49.792653            -88.506389  \n",
       "1604010854             68.874414            -28.777372            -49.792653  \n",
       "1604010856             42.693629             68.874414            -28.777372  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_predict_processed.shape)\n",
    "df_predict_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above featurized prediction data should be identical in terms of structure and schema to the featurized training data we explored above. This is what is expected by the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010851\n",
      "model=system.cpu, anomaly_probability=0.0287, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0443, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0016, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010852\n",
      "model=system.cpu, anomaly_probability=0.0218, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0419, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0029, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010853\n",
      "model=system.cpu, anomaly_probability=0.0254, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0511, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0059, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010854\n",
      "model=system.cpu, anomaly_probability=0.0276, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0411, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0054, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010856\n",
      "model=system.cpu, anomaly_probability=0.0295, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0365, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0028, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010857\n",
      "model=system.cpu, anomaly_probability=0.0402, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0302, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0029, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010858\n",
      "model=system.cpu, anomaly_probability=0.0425, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0213, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0054, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010859\n",
      "model=system.cpu, anomaly_probability=0.0477, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0202, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0064, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010860\n",
      "model=system.cpu, anomaly_probability=0.062, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0124, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0092, anomaly_flag=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predictions for time 1604010861\n",
      "model=system.cpu, anomaly_probability=0.0675, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0002, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0047, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0127, anomaly_flag=0\n"
     ]
    }
   ],
   "source": [
    "# for each recent feature vector, get a prediction\n",
    "for time_idx, row in df_predict_processed.iterrows():\n",
    "    \n",
    "    print('-'*100)\n",
    "    print(f'predictions for time {time_idx}')\n",
    "    \n",
    "    # convert our row into the expected 'flattened' feature vector\n",
    "    df_tmp = row.to_frame().transpose()\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        # pull out relevant array of features for the model in question\n",
    "        X_predict = df_tmp[df_tmp.columns[df_tmp.columns.str.startswith(model)]].values\n",
    "        \n",
    "        # call the predict_proba() and predict() methods on the trained data in order to make a prediction\n",
    "        anomaly_probability = round(models[model].predict_proba(X_predict)[-1][1],4)\n",
    "        anomaly_flag = models[model].predict(X_predict)[-1]\n",
    "        \n",
    "        print(f'model={model}, anomaly_probability={anomaly_probability}, anomaly_flag={anomaly_flag}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we should generally see low `anomaly_probability` values (assuming nothing has blown up on the host you used between the time you ran the training cells above and the predictions above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just do one last little thing to try show what is going on here and why we put so much effort and focus into the featurization above.\n",
    "\n",
    "We will take one of the last feature vectors we predicted on for each model, randomly shuffle the values around so as to make an unusual looking observation, and see what sort of an anomaly probability that gives us. (hint: it should be higher then those above :) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=system.cpu, anomaly_probability=1.0, anomaly_flag=1\n",
      "model=system.load, anomaly_probability=1.0, anomaly_flag=1\n",
      "model=system.net, anomaly_probability=0.0031, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.1227, anomaly_flag=1\n"
     ]
    }
   ],
   "source": [
    "# take last row from prediction data, shuffle the columns around\n",
    "df_predict_shuffled = df_predict_processed.tail(1).transpose().sample(frac=1).transpose()\n",
    "# ensure has same column names as expected by the models\n",
    "df_predict_shuffled.columns = df_predict_processed.columns # rename things to really shuffle things\n",
    "for model in models:\n",
    "    X_predict = df_predict_shuffled[df_predict_shuffled.columns[df_predict_shuffled.columns.str.startswith(model)]].values\n",
    "    anomaly_probability = round(models[model].predict_proba(X_predict)[-1][1],4)\n",
    "    anomaly_flag = models[model].predict(X_predict)[-1]\n",
    "    print(f'model={model}, anomaly_probability={anomaly_probability}, anomaly_flag={anomaly_flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We _should_ see some higher anomaly probabilities above than in the predictions we had previously made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what _is_ the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and lift the lid a little on what the model actually is and how it is calculating anomaly probabilities lets take a look at one trained model and what it actually is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for chart system.cpu:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'contamination': 0.001,\n",
       " 'n_components': 2,\n",
       " 'n_selected_components': 2,\n",
       " 'copy': True,\n",
       " 'whiten': False,\n",
       " 'svd_solver': 'auto',\n",
       " 'tol': 0.0,\n",
       " 'iterated_power': 'auto',\n",
       " 'random_state': None,\n",
       " 'weighted': True,\n",
       " 'standardization': True,\n",
       " '_classes': 2,\n",
       " 'scaler_': StandardScaler(),\n",
       " 'detector_': PCA(n_components=2),\n",
       " 'n_components_': 2,\n",
       " 'components_': array([[-5.50935006e-18, -1.77822178e-17, -1.40549313e-17,\n",
       "         -9.27479059e-19, -7.87135951e-18,  8.92768564e-18,\n",
       "         -2.91829723e-18,  4.26211759e-18, -2.35022278e-18,\n",
       "         -2.22404072e-18, -5.55261119e-19,  0.00000000e+00,\n",
       "         -2.40988483e-02,  2.56604744e-03, -3.15746159e-03,\n",
       "          2.22386041e-02, -2.97609182e-03,  7.37389491e-03,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -1.20062730e-01, -2.73585893e-02,  8.44771381e-02,\n",
       "          1.21242016e-01,  2.88370008e-02, -8.05597978e-02,\n",
       "         -1.37875501e-01,  3.10262560e-03,  1.33378532e-01,\n",
       "          1.30284568e-01, -4.66795633e-03, -1.23777343e-01,\n",
       "         -2.99415331e-01, -7.84333948e-02,  2.64223671e-01,\n",
       "          2.93179894e-01,  4.97221105e-02, -2.79669530e-01,\n",
       "         -3.62253057e-01, -3.41546450e-03,  3.78573303e-01,\n",
       "          3.52449397e-01, -6.36657441e-02, -3.87698621e-01],\n",
       "        [ 1.47754716e-17, -7.46934657e-18, -7.08993522e-18,\n",
       "         -2.52680947e-18, -1.18090278e-18, -7.14709333e-18,\n",
       "          9.57224220e-18,  5.11936405e-18, -2.84742821e-18,\n",
       "          4.68372224e-18, -3.56748727e-19, -0.00000000e+00,\n",
       "         -5.43149470e-03, -1.91458338e-02, -2.01817158e-02,\n",
       "         -1.49325565e-05,  1.42087076e-02,  1.73638959e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -4.34108175e-02, -1.53843882e-01, -1.00653827e-01,\n",
       "          4.61967003e-02,  1.59341395e-01,  1.08816723e-01,\n",
       "         -9.45494288e-02, -1.82683709e-01, -9.28852018e-02,\n",
       "          8.80373358e-02,  1.71307502e-01,  8.63163294e-02,\n",
       "         -7.86567354e-02, -3.39949826e-01, -2.09127089e-01,\n",
       "          1.03008172e-01,  3.41393980e-01,  1.85026766e-01,\n",
       "         -1.96467432e-01, -4.17661925e-01, -1.84162124e-01,\n",
       "          2.42672198e-01,  4.18891722e-01,  1.41271878e-01]]),\n",
       " 'n_selected_components_': 2,\n",
       " 'w_components_': array([0.0664242 , 0.06379451]),\n",
       " 'selected_components_': array([[-5.50935006e-18, -1.77822178e-17, -1.40549313e-17,\n",
       "         -9.27479059e-19, -7.87135951e-18,  8.92768564e-18,\n",
       "         -2.91829723e-18,  4.26211759e-18, -2.35022278e-18,\n",
       "         -2.22404072e-18, -5.55261119e-19,  0.00000000e+00,\n",
       "         -2.40988483e-02,  2.56604744e-03, -3.15746159e-03,\n",
       "          2.22386041e-02, -2.97609182e-03,  7.37389491e-03,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -1.20062730e-01, -2.73585893e-02,  8.44771381e-02,\n",
       "          1.21242016e-01,  2.88370008e-02, -8.05597978e-02,\n",
       "         -1.37875501e-01,  3.10262560e-03,  1.33378532e-01,\n",
       "          1.30284568e-01, -4.66795633e-03, -1.23777343e-01,\n",
       "         -2.99415331e-01, -7.84333948e-02,  2.64223671e-01,\n",
       "          2.93179894e-01,  4.97221105e-02, -2.79669530e-01,\n",
       "         -3.62253057e-01, -3.41546450e-03,  3.78573303e-01,\n",
       "          3.52449397e-01, -6.36657441e-02, -3.87698621e-01],\n",
       "        [ 1.47754716e-17, -7.46934657e-18, -7.08993522e-18,\n",
       "         -2.52680947e-18, -1.18090278e-18, -7.14709333e-18,\n",
       "          9.57224220e-18,  5.11936405e-18, -2.84742821e-18,\n",
       "          4.68372224e-18, -3.56748727e-19, -0.00000000e+00,\n",
       "         -5.43149470e-03, -1.91458338e-02, -2.01817158e-02,\n",
       "         -1.49325565e-05,  1.42087076e-02,  1.73638959e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -4.34108175e-02, -1.53843882e-01, -1.00653827e-01,\n",
       "          4.61967003e-02,  1.59341395e-01,  1.08816723e-01,\n",
       "         -9.45494288e-02, -1.82683709e-01, -9.28852018e-02,\n",
       "          8.80373358e-02,  1.71307502e-01,  8.63163294e-02,\n",
       "         -7.86567354e-02, -3.39949826e-01, -2.09127089e-01,\n",
       "          1.03008172e-01,  3.41393980e-01,  1.85026766e-01,\n",
       "         -1.96467432e-01, -4.17661925e-01, -1.84162124e-01,\n",
       "          2.42672198e-01,  4.18891722e-01,  1.41271878e-01]]),\n",
       " 'selected_w_components_': array([0.0664242 , 0.06379451]),\n",
       " 'decision_scores_': array([232.8754145 , 213.88435525, 191.88751269, ..., 172.72135443,\n",
       "        177.61760052, 197.07612116]),\n",
       " 'threshold_': 1318.949671284241,\n",
       " 'labels_': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " '_mu': 152.23721835358486,\n",
       " '_sigma': 77.88171364796523}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets pick our first trained model\n",
    "model_to_explore = charts_in_scope[0]\n",
    "\n",
    "print(f'model for chart {model_to_explore}:')\n",
    "models[model_to_explore].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above we see the various objects, mostly array's of numbers, that make up the internal state of the trained model. \n",
    "\n",
    "**Note**: for different types of models you will see different things in here. The below cells all assume `model='pca'` to walk through the example of how the default PCA model calculates an anomaly probability. Also for simplicity when we initialized the PCA model we set `n_selected_components=2` to make the calculations below easier to follow by telling PyOD to just use the first 2 principle components when calculating the anomaly scores. In the actual anomalies collector we use all the principle components.\n",
    "\n",
    "For PCA the main things of relevance below will be: \n",
    "\n",
    "- `selected_components_`: The actual principle components we want to use when calculating the anomaly score (aka `decision_score`).\n",
    "- `selected_w_components_`: The weights applied to each selected component, the first few typically matter more as they capture most of the variance in the original training data. \n",
    "- `decision_scores_`: The raw anomaly scores on all of the training observations, used to convert the anomaly score into something that more looks like an anomaly probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at the 'training' source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at what the PCA model does when it trains a model. W can see from the below that most of what is going on is fitting a [PCA from Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to the training data `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Fit detector. y is ignored in unsupervised methods.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The input samples.\n",
       "\n",
       "        y : Ignored\n",
       "            Not used, present for API consistency by convention.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        self : object\n",
       "            Fitted estimator.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# validate inputs X and y (optional)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# PCA is recommended to use on the standardized data (zero mean and\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# unit variance).\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_scalar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn_PCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mwhiten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0msvd_solver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd_solver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0miterated_power\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# copy the attributes from the sklearn PCA object\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# validate the number of components to be used for outlier detection\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0minclude_left\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_right\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mparam_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n_selected_components_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# use eigenvalues as the weights of eigenvectors\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# outlier scores is the sum of the weighted distances between each\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# sample to the eigenvectors. The eigenvectors with smaller\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# eigenvalues have more influence\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Not all eigenvectors are used, only n_selected_components_ smallest\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# are used since they better reflect the variance change\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                    \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                      \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_decision_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\pca.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.fit??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at the 'prediction' source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the source code for generating the anomaly probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Predict the probability of a sample being outlier. Two approaches\n",
       "        are possible:\n",
       "\n",
       "        1. simply use Min-max conversion to linearly transform the outlier\n",
       "           scores into the range of [0,1]. The model must be\n",
       "           fitted first.\n",
       "        2. use unifying scores, see :cite:`kriegel2011interpreting`.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The input samples.\n",
       "\n",
       "        method : str, optional (default='linear')\n",
       "            probability conversion method. It must be one of\n",
       "            'linear' or 'unify'.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        outlier_probability : numpy array of shape (n_samples,)\n",
       "            For each observation, tells whether or not\n",
       "            it should be considered as an outlier according to the\n",
       "            fitted model. Return the outlier probability, ranging\n",
       "            in [0,1].\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'decision_scores_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'threshold_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'unify'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# turn output into probability\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpre_erf_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_scores\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sigma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0merf_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_erf_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merf_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                             \u001b[1;34m'is not a valid probability conversion method'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.predict_proba??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see its getting scores from some `decision_function()` method, so lets look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Predict raw anomaly score of X using the fitted detector.\n",
       "\n",
       "        The anomaly score of an input sample is computed based on different\n",
       "        detector algorithms. For consistency, outliers are assigned with\n",
       "        larger anomaly scores.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The training input samples. Sparse matrices are accepted only\n",
       "            if they are supported by the base estimator.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        anomaly_scores : numpy array of shape (n_samples,)\n",
       "            The anomaly score of the input samples.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'components_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w_components_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\pca.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.decision_function??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here what actually look like relativley straightforward calculations, so lets try step through them below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok so lets step through that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the cells above show the PyOD code under the hood - lets step through and recreate the a predicted score, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by getting our feature vector that we would like an anomaly probability for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature vector\n",
      "(1, 54)\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "  -0.0835422   0.0835422   0.08333333  0.0835422   0.         -0.0837521\n",
      "   0.          0.          0.08333333  0.          0.          0.\n",
      "   0.0012658  -0.083962   -0.00083753 -0.00041983  0.          0.\n",
      "  -0.33353583  0.08312237 -0.0845896   0.16645467  0.0837521   0.08375207]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# get our feature vector for a random observation from our prediction data\n",
    "X = df_predict_processed[df_predict_processed.columns[df_predict_processed.columns.str.startswith(model_to_explore)]].sample(1).values\n",
    "\n",
    "print('feature vector')\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the principle components the model will use to calculate our anomaly score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected components learned by model\n",
      "(2, 54)\n",
      "[[-5.50935006e-18 -1.77822178e-17 -1.40549313e-17 -9.27479059e-19\n",
      "  -7.87135951e-18  8.92768564e-18 -2.91829723e-18  4.26211759e-18\n",
      "  -2.35022278e-18 -2.22404072e-18 -5.55261119e-19  0.00000000e+00\n",
      "  -2.40988483e-02  2.56604744e-03 -3.15746159e-03  2.22386041e-02\n",
      "  -2.97609182e-03  7.37389491e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.20062730e-01 -2.73585893e-02\n",
      "   8.44771381e-02  1.21242016e-01  2.88370008e-02 -8.05597978e-02\n",
      "  -1.37875501e-01  3.10262560e-03  1.33378532e-01  1.30284568e-01\n",
      "  -4.66795633e-03 -1.23777343e-01 -2.99415331e-01 -7.84333948e-02\n",
      "   2.64223671e-01  2.93179894e-01  4.97221105e-02 -2.79669530e-01\n",
      "  -3.62253057e-01 -3.41546450e-03  3.78573303e-01  3.52449397e-01\n",
      "  -6.36657441e-02 -3.87698621e-01]\n",
      " [ 1.47754716e-17 -7.46934657e-18 -7.08993522e-18 -2.52680947e-18\n",
      "  -1.18090278e-18 -7.14709333e-18  9.57224220e-18  5.11936405e-18\n",
      "  -2.84742821e-18  4.68372224e-18 -3.56748727e-19 -0.00000000e+00\n",
      "  -5.43149470e-03 -1.91458338e-02 -2.01817158e-02 -1.49325565e-05\n",
      "   1.42087076e-02  1.73638959e-02 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -4.34108175e-02 -1.53843882e-01\n",
      "  -1.00653827e-01  4.61967003e-02  1.59341395e-01  1.08816723e-01\n",
      "  -9.45494288e-02 -1.82683709e-01 -9.28852018e-02  8.80373358e-02\n",
      "   1.71307502e-01  8.63163294e-02 -7.86567354e-02 -3.39949826e-01\n",
      "  -2.09127089e-01  1.03008172e-01  3.41393980e-01  1.85026766e-01\n",
      "  -1.96467432e-01 -4.17661925e-01 -1.84162124e-01  2.42672198e-01\n",
      "   4.18891722e-01  1.41271878e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('selected components learned by model')\n",
    "selected_components = models[model_to_explore].selected_components_\n",
    "print(selected_components.shape)\n",
    "print(selected_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the weighting that the model will apply to each component when working out a weighted distance that will form the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected components weights set by model\n",
      "(2,)\n",
      "[0.0664242  0.06379451]\n"
     ]
    }
   ],
   "source": [
    "print('selected components weights set by model')\n",
    "selected_w_components = models[model_to_explore].selected_w_components_\n",
    "print(selected_w_components.shape)\n",
    "print(selected_w_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just call `predict_proba(X)` to get the score we will try to recreate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly probability [p(anomaly), p(not anomaly)]\n",
      "(1, 2)\n",
      "[[0.95233415 0.04766585]]\n"
     ]
    }
   ],
   "source": [
    "print('anomaly probability [p(anomaly), p(not anomaly)]')\n",
    "anomaly_probability = models[model_to_explore].predict_proba(X)\n",
    "print(anomaly_probability.shape)\n",
    "print(anomaly_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Standardize the feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to standardize the data as this is a default common practice when fitting a PCA to data. \n",
    "\n",
    "This is the default here which is good as it means that if you define any [custom models](https://github.com/andrewm4894/netdata/tree/anomalies-collector/collectors/python.d.plugin/anomalies#custom-models) in your `anomalies.conf` file, you dont need to worry about them not being on the same or similar scales (e.g. cpu % vs disk usage etc) as that is all taken care of internally by the PyOD model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.78400805e-20 -1.73520241e-19 -1.73520241e-19 -5.78400805e-20\n",
      "  -1.15680161e-19  5.78400805e-20  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.66434319e+00  1.66453420e+00\n",
      "   1.66041734e+00  1.66457873e+00 -1.15624045e-04 -1.66817088e+00\n",
      "  -1.94377014e-04  1.93303092e-19  2.78385657e+00 -1.93995108e-04\n",
      "  -1.93995108e-04 -1.28868728e-19  1.03478544e-02 -6.73733354e-01\n",
      "  -6.67494592e-03 -3.27589677e-03  9.46024400e-05  7.02613199e-07\n",
      "  -2.03545305e+00  5.07310607e-01 -5.16193632e-01  1.01586725e+00\n",
      "   5.11194905e-01  5.11216024e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = models[model_to_explore].scaler_.transform(X)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate distance from each selected component "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to work out the distance of our feature vector to each of the selected components. \n",
    "\n",
    "This is the core part of what is going on when calculating an anomaly score using this model. \n",
    "\n",
    "If we have a strange feature vector then its going to be something we have not really seen before and so will not fit well into the lower dimensional representation learned by the PCA model. Hence it will have a somewhat larger distance from the selected principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[5.08366156 5.34926827]]\n"
     ]
    }
   ],
   "source": [
    "distance = cdist(X_scaled, selected_components)\n",
    "print(distance.shape)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: These distance numbers are just numbers, where bigger means more distant, but on their own are hard to interpret it terms of what they mean. So the next step will be to try and go from the weighted distance score to an anomaly probability by comparing the anomay score with all those we saw within the training data. It's the training data that will be our yardstick for trying to say just how anomalous a new observation is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Use a weighted average distance as the anomaly score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a weighted average of the distances, where the weights for each component will, by default, be related to the amount of variance in the original training data that each component 'explained' or represented (we can see this in the PyOD code [here](https://github.com/yzhao062/pyod/blob/master/pyod/models/pca.py#L252))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly score\n",
      "[160.38482028]\n"
     ]
    }
   ],
   "source": [
    "print('anomaly score')\n",
    "anomaly_score = np.sum(distance / selected_w_components, axis=1).ravel()\n",
    "print(anomaly_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Convert anomaly score into anomaly probabilities based on the anomaly scores of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the decision scores we calculated from basically running the prediction process back over the training data when we originally fit our model. \n",
    "\n",
    "We will use the distribution of scores in the training data to try and re-scale our raw anomaly score to look more like something that can pass as a probability.\n",
    "\n",
    "**Note**: Strictly speaking this \"anomaly probability\" is not really a \"real\" probability in the sense of being some sort of more formal or theoretical output from some probabilistic process we have statistically modeled directly. Rather, its just a sensible re-scaling of our raw score based on what we saw in the training data. So a high 'probability' here really just means an unusual value in reference to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95233415 0.04766585]]\n"
     ]
    }
   ],
   "source": [
    "# get the raw anomaly scores from the training data\n",
    "train_anomaly_scores = models[model_to_explore].decision_scores_\n",
    "\n",
    "# create empty array for probabilities to go into\n",
    "anomaly_probability_manual_calc = np.zeros([X.shape[0], int(models[model_to_explore]._classes)])\n",
    "\n",
    "# create a scaler to rescale raw anomaly score to look more like a probability and be on the 0, 1 range\n",
    "scaler = MinMaxScaler().fit(train_anomaly_scores.reshape(-1, 1))\n",
    "\n",
    "# transform anomaly score into a probability by rescaling it based on the training data and clipping at 1\n",
    "anomaly_probability_manual_calc[:, 1] = scaler.transform(anomaly_score.reshape(-1, 1)).ravel().clip(0, 1)\n",
    "\n",
    "# use 1 - p(anomaly) as p(not anomaly)\n",
    "anomaly_probability_manual_calc[:, 0] = 1 - anomaly_probability_manual_calc[:, 1]\n",
    "\n",
    "print(anomaly_probability_manual_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do they match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95233415 0.04766585]]\n",
      "[[0.95233415 0.04766585]]\n",
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# do they match?\n",
    "print(anomaly_probability)\n",
    "print(anomaly_probability_manual_calc)\n",
    "print(anomaly_probability == anomaly_probability_manual_calc)\n",
    "assert np.sum(anomaly_probability == anomaly_probability_manual_calc) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "....phew, thats it! Go get yourself a coffee :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
